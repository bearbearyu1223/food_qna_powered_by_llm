import openai
from termcolor import colored
from typing import List
import streamlit as st 

from redis_db import create_redis_client, get_redis_results
from config import CHAT_MODEL, COMPLETION_MODEL, INDEX_NAME

redis_client = create_redis_client()

class Message: 
    def __init__(self, role:str, content:str) -> None:
        self.role = role 
        self.content = content

    def message(self): 
        return {
            'role': self.role, 
            'content': self.content
        }

class LLMAssistant: 
    def __init__(self) -> None:
        self.conversation_history = [] 

    def _get_assistant_response(self, prompt): 
        '''
        Model inputs to gpt-3.5.turbo are defined by three types of messages, corresponding 
        to three roles: system, user, assistant 
        parameters = {
        'model': 'gpt-3.5.turbo', 
        'messages': [{"role": "system", "content": ...}, 
                    {"role": "user", "content": ...}, 
                    {"role": "assistant", "content": ...}]
        }
        - The system message helps set the behavior of the assistant (e.g., the identity of the assistant). 
        - The user messages help instruct the assistant. They can be generated by the 
          end users of an application, or set by a developer as an instruction. 
        - The assistant messages help store prior response. They can also be written by 
          a developer to help give examples of desired behavior. 
        '''
        try: 
            completion = openai.ChatCompletion.create(
                model=CHAT_MODEL, 
                messages=prompt, 
                temperature=0.5
            )
            response_message = Message(
                completion['choices'][0]['message']['role'], 
                completion['choices'][0]['message']['content']
            )
            return response_message.message()
        except Exception as e: 
            return f'Request failed with expection {e}.'
    
    def _get_search_results_from_db(self, prompt:str)->str: 
        latest_query = prompt
        retrieved_raw_content=get_redis_results(
            redis_conn=redis_client, 
            query=latest_query, 
            index_name=INDEX_NAME
        ).text[0]
        return retrieved_raw_content

    def ask_llm_assistant(self, next_user_prompt:List):
        [self.conversation_history.append(x) for x in next_user_prompt]
        assistant_response = self._get_assistant_response(self.conversation_history)
        if 'certainly' in assistant_response['content'].lower(): 
            question_extract = openai.Completion.create(model=COMPLETION_MODEL,
            prompt=f'''
            Extract the user's latest question from this conversation:\
            {self.conversation_history}. Extract it as a sentence stating the question.")
            ''')
            retrieved_results= self._get_search_results_from_db(question_extract['choices'][0]['text'])

            if retrieved_results != '': 
                self.conversation_history.insert(
                -1,\
                {"role": 'system',
                 "content": f'''
                 Answer the user's question with fewer words using this content: {retrieved_results}. 
                 If you cannot answer the question, say 'Sorry, I don't know the answer to this one'
                 '''
                })
            assistant_response = self._get_assistant_response(self.conversation_history )
            self.conversation_history.append(assistant_response)
            return assistant_response
        else:
            self.conversation_history.append(assistant_response)
            return assistant_response 
    
    def pretty_print_converstation_history(self, colorize_assistant_replies=True):
        for entry in self.conversation_history: 
            if entry['role']=='system':
                pass
            else: 
                prefix = entry['role']
                content = entry['content']
                if colorize_assistant_replies and entry['role']=='assistant': 
                    output = colored(f'{prefix}:\n{content}, green')
                else: 
                    output = colored(f'{prefix}:\n{content}, blue')
                print(output)